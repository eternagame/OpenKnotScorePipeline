{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bff798",
   "metadata": {},
   "source": [
    "# Generate RDATs for upload to Eterna\n",
    "\n",
    "This notebook takes an input dataframe of sequences with predictions and scoring metrics and generates a collection of RDAT files to be uploaded to Eterna for score distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bddd4c-02ff-4ab7-baa1-feca01b8f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from openknotscore.utils import load_rdat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38747bd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original RDAT\n",
    "rdat_name = input(\n",
    "    \"Name of the source RDAT file in the data/rdats folder\"\n",
    ")\n",
    "rdat, constructName = load_rdat(f'../data/rdats/{rdat_name}')\n",
    "\n",
    "# Input dataframe to be saved to RDATs\n",
    "data = pd.read_pickle(\"../data/data_processed.pkl\")\n",
    "\n",
    "# Update this to match the construct in the orginal RDAT\n",
    "job = input(\n",
    "    \"Job Name: Where the subsets are stored in SCRATCH (the same as the job name specified in the split date notebook)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c06e4",
   "metadata": {},
   "source": [
    "## Add OKS and best predictions to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the sequences present in the original RDAT\n",
    "for sequence in rdat.constructs[constructName].data:\n",
    "    seq = sequence.annotations[\"sequence\"][0]\n",
    "    annotationList = sequence.annotations.setdefault('Eterna', [])\n",
    "    \n",
    "    # There may be no processed data (OKS, predictions) associated with the sequence\n",
    "    # if the sequence had low-quality or missing reactivity data, so we skip those rows\n",
    "    row = data.loc[data['sequence'] == seq].squeeze()\n",
    "    if row.empty:\n",
    "        print(\"No processed data\")\n",
    "        continue\n",
    "\n",
    "    # Add annotations with the processed data to the RDAT\n",
    "    annotationList.append(f\"score:openknot_score:{row['ensemble_OKS']:.6f}\")\n",
    "    annotationList.append(f\"score:eterna_classic_score:{row['ensemble_ECS']:.6f}\")\n",
    "    annotationList.append(f\"score:crossed_pair_quality_score:{row['ensemble_CPQ']:.6f}\")\n",
    "    annotationList.append(f\"best_fit:tags:{','.join(row['ensemble_tags'])}\")\n",
    "    annotationList.append(f\"best_fit:structures:{','.join(row['ensemble_structures'])}\")\n",
    "    annotationList.append(f\"best_fit:eterna_classic_scores:{','.join([f'{v:.6f}' for v in row['ensemble_structures_ecs']])}\")\n",
    "\n",
    "    print(annotationList)\n",
    "    \n",
    "# Save the RDAT with updated annotations\n",
    "rdat.save(f'../data/{job}_processed.rdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355405e",
   "metadata": {},
   "source": [
    "## Split into multiple RDATS for upload (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f97b5-8747-4154-a446-f42c93814997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# How many sequences to store in each output RDAT. Eterna has size limits on uploaded files,\n",
    "# so size this as necessary to stay under 15MB per RDAT while limiting total rdats created.\n",
    "outputSeq = 2000\n",
    "totalRdats = math.ceil(len(data)/outputSeq)\n",
    "\n",
    "inputFile = f\"../data/{job}_processed.rdat\"\n",
    "\n",
    "for i in range(totalRdats):\n",
    "    # Reset the RDAT object\n",
    "    rdat, constructName = load_rdat(inputFile)\n",
    "    assert len(rdat.constructs) == 1\n",
    "    constructName = list(rdat.constructs.keys())[0]\n",
    "    data = rdat.constructs[constructName].data\n",
    "\n",
    "    # Subset the RDAT data for saving.\n",
    "    rdat.constructs[constructName].data = data[i*outputSeq:(i+1)*outputSeq]\n",
    "    rdat.values[constructName] = [row.values for row in data[i*outputSeq:(i+1)*outputSeq]]\n",
    "    rdat.errors[constructName] = [row.errors for row in data[i*outputSeq:(i+1)*outputSeq]]\n",
    "\n",
    "    rdat.save(f\"../data/upload_rdats/{job}-{i}.rdat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
